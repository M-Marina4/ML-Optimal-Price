{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eda10da-3227-48fc-9548-e7bb2a4f70d0",
   "metadata": {},
   "source": [
    "# Optimal Price Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee9921-6ac2-434a-9a01-5c2fe7db8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a9ba3-8431-4c64-824a-daacff9c9af5",
   "metadata": {},
   "source": [
    "### Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487a405a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((   Long  Lat    Size  Light               Price_Booking1  \\\n",
       "  0     5  -54  medium      0  (25.82068271676904, 0.7519)   \n",
       "  1    15   34   large      1   (60.5614418412558, 0.0441)   \n",
       "  2    52   33   small      1  (64.77841886497515, 0.0978)   \n",
       "  3    36  -32   small      0  (43.51319658191266, 0.5933)   \n",
       "  4    29   49  medium      0  (9.023792361018867, 0.9172)   \n",
       "  \n",
       "                   Price_Booking2                Price_Booking3  \\\n",
       "  0   (77.29030734504285, 0.1281)   (26.42977169141242, 0.7555)   \n",
       "  1   (44.09864114154084, 0.1872)  (12.864575260713796, 0.8316)   \n",
       "  2   (63.79016149960564, 0.1055)  (4.2689974099545775, 0.9454)   \n",
       "  3  (20.583513389202647, 0.8548)  (51.335440281471314, 0.5031)   \n",
       "  4   (34.06932873577466, 0.6672)  (42.200420426573835, 0.5574)   \n",
       "  \n",
       "                  Price_Booking4                Price_Booking5  \\\n",
       "  0  (62.99594808649998, 0.2545)  (29.367952575023835, 0.7252)   \n",
       "  1  (22.15931742842302, 0.6385)   (66.75211626816896, 0.0236)   \n",
       "  2   (99.1170238991595, 0.0048)  (10.377996166352721, 0.9134)   \n",
       "  3  (88.96013764481202, 0.1404)   (10.176719125181155, 0.944)   \n",
       "  4  (54.54040575218243, 0.3914)   (9.604716563777105, 0.9414)   \n",
       "  \n",
       "                   Price_Booking6  ...              Price_Booking511  \\\n",
       "  0  (12.498892405599015, 0.9243)  ...  (15.452548500178054, 0.8098)   \n",
       "  1  (56.097437492463165, 0.0706)  ...  (36.252092499116415, 0.2932)   \n",
       "  2  (18.369220836111012, 0.8119)  ...   (38.22115060567866, 0.3989)   \n",
       "  3   (80.58790465316733, 0.2008)  ...   (65.66340019323884, 0.3075)   \n",
       "  4  (12.166224412048997, 0.9314)  ...   (9.335770325450078, 0.8544)   \n",
       "  \n",
       "                 Price_Booking512              Price_Booking513  \\\n",
       "  0    (79.16898963165264, 0.108)  (42.128169836948345, 0.4888)   \n",
       "  1   (97.94984356954937, 0.0003)   (83.55961793769666, 0.0026)   \n",
       "  2   (4.443929498817734, 0.8718)   (94.07931546786537, 0.0075)   \n",
       "  3   (54.79499263500919, 0.4246)   (5.085965871041765, 0.8802)   \n",
       "  4  (41.233911400951904, 0.5271)   (62.93835936133358, 0.2676)   \n",
       "  \n",
       "                Price_Booking514              Price_Booking515  \\\n",
       "  0  (90.40108811925055, 0.0577)   (95.08379435621892, 0.0434)   \n",
       "  1  (46.73238535091752, 0.1442)  (26.315070270634035, 0.5035)   \n",
       "  2  (64.28148553268129, 0.0959)   (50.52228570735669, 0.2264)   \n",
       "  3   (98.82202564164659, 0.083)   (59.43480296481752, 0.3801)   \n",
       "  4  (87.14023119112295, 0.0898)    (88.1610349091075, 0.0857)   \n",
       "  \n",
       "                 Price_Booking516             Price_Booking517  \\\n",
       "  0   (98.59868991395079, 0.0348)   (66.28525118972154, 0.209)   \n",
       "  1   (96.44073701826878, 0.0004)  (8.402180767240308, 0.8583)   \n",
       "  2   (86.83656236684291, 0.0155)  (76.91744425841044, 0.0374)   \n",
       "  3  (41.154463469789526, 0.5986)  (9.927405560835512, 0.8888)   \n",
       "  4   (38.64205874576124, 0.5754)  (12.61911415987419, 0.8676)   \n",
       "  \n",
       "                 Price_Booking518              Price_Booking519  \\\n",
       "  0  (10.438122191545451, 0.8847)    (65.58403874417343, 0.219)   \n",
       "  1   (29.320140891961966, 0.448)   (2.347873700296099, 0.9208)   \n",
       "  2   (33.86871398561934, 0.4942)  (0.4159661590927177, 0.9249)   \n",
       "  3   (95.51171633092292, 0.0999)    (15.3399616599158, 0.8736)   \n",
       "  4   (58.14450114233951, 0.3303)   (62.25082481310573, 0.2868)   \n",
       "  \n",
       "                 Price_Booking520  \n",
       "  0    (67.03639353949687, 0.207)  \n",
       "  1   (54.38055023149264, 0.0792)  \n",
       "  2   (91.44157368958481, 0.0103)  \n",
       "  3   (58.67192259210717, 0.4038)  \n",
       "  4  (54.831370666551585, 0.3759)  \n",
       "  \n",
       "  [5 rows x 524 columns],\n",
       "                 Long           Lat         Light\n",
       "  count  10000.000000  10000.000000  10000.000000\n",
       "  mean       0.441600     -0.474000      0.506800\n",
       "  std       34.860994     35.225817      0.499979\n",
       "  min      -60.000000    -60.000000      0.000000\n",
       "  25%      -29.000000    -31.000000      0.000000\n",
       "  50%        0.000000     -1.000000      1.000000\n",
       "  75%       31.000000     30.000000      1.000000\n",
       "  max       60.000000     60.000000      1.000000,\n",
       "  Long                 int64\n",
       "  Lat                  int64\n",
       "  Size                object\n",
       "  Light                int64\n",
       "  Price_Booking1      object\n",
       "                       ...  \n",
       "  Price_Booking516    object\n",
       "  Price_Booking517    object\n",
       "  Price_Booking518    object\n",
       "  Price_Booking519    object\n",
       "  Price_Booking520    object\n",
       "  Length: 524, dtype: object),\n",
       " (   Long  Lat    Size  Light                Price_Booking1  \\\n",
       "  0    11   -8   small      1   (44.07422740778878, 0.2244)   \n",
       "  1   -23   50   large      0  (27.403085749044997, 0.6838)   \n",
       "  2    10  -45  medium      0   (32.49922734531039, 0.6368)   \n",
       "  3    -4    3   small      1   (92.82272915578096, 0.0011)   \n",
       "  4    -2   15   small      1   (49.80177382910645, 0.1483)   \n",
       "  \n",
       "                   Price_Booking2                Price_Booking3  \\\n",
       "  0  (10.235745495054404, 0.8771)   (77.44432192100861, 0.0115)   \n",
       "  1   (67.88625315230517, 0.1343)   (58.481870400767434, 0.224)   \n",
       "  2   (27.27239937360443, 0.7202)   (36.20418901494742, 0.5888)   \n",
       "  3  (24.132065502164757, 0.6006)   (63.09560763988213, 0.0423)   \n",
       "  4   (54.07334498175166, 0.1074)  (45.903234713953736, 0.1989)   \n",
       "  \n",
       "                   Price_Booking4               Price_Booking5  \\\n",
       "  0  (32.682854325706636, 0.4374)  (93.07005020369597, 0.0016)   \n",
       "  1   (56.95623287755157, 0.2431)  (4.993203977397098, 0.9579)   \n",
       "  2   (81.40103513141597, 0.0835)  (71.81075706852077, 0.1446)   \n",
       "  3   (33.327256606541425, 0.403)  (33.69975089548419, 0.3979)   \n",
       "  4    (77.4330848736851, 0.0111)  (65.96155090109079, 0.0379)   \n",
       "  \n",
       "                   Price_Booking6  ...              Price_Booking511  \\\n",
       "  0   (59.55342009850416, 0.0712)  ...   (3.503511792465819, 0.8693)   \n",
       "  1   (42.47182196384385, 0.4534)  ...  (21.379118386361394, 0.7227)   \n",
       "  2  (18.065003797032787, 0.8636)  ...   (17.42772963166037, 0.7843)   \n",
       "  3   (73.18542895745563, 0.0147)  ...   (69.74082104797938, 0.0195)   \n",
       "  4   (5.084813285843259, 0.9554)  ...   (66.97356607076182, 0.0311)   \n",
       "  \n",
       "                 Price_Booking512              Price_Booking513  \\\n",
       "  0  (21.207831688891897, 0.6324)  (37.472733112480896, 0.3145)   \n",
       "  1   (58.91370302091187, 0.2023)   (4.511084912965702, 0.8782)   \n",
       "  2   (7.484976054849901, 0.8631)     (25.601585429981, 0.6956)   \n",
       "  3    (38.80884537040286, 0.271)    (63.16126548911956, 0.039)   \n",
       "  4    (91.1566259740697, 0.0018)   (85.68419936773684, 0.0037)   \n",
       "  \n",
       "                Price_Booking514              Price_Booking515  \\\n",
       "  0  (17.68477270798783, 0.7076)  (3.9349006656278496, 0.8869)   \n",
       "  1  (49.94310488165724, 0.3095)   (11.68847681410703, 0.8466)   \n",
       "  2   (50.3850166054486, 0.3494)  (16.117362334552887, 0.8151)   \n",
       "  3   (88.27001407634896, 0.002)   (74.70630932807055, 0.0114)   \n",
       "  4  (75.55400762308903, 0.0127)  (48.515525854018584, 0.1555)   \n",
       "  \n",
       "                 Price_Booking516             Price_Booking517  \\\n",
       "  0   (90.75592780176181, 0.0021)   (57.12871533905361, 0.082)   \n",
       "  1   (69.85385620221606, 0.1142)  (30.52089300740838, 0.6134)   \n",
       "  2  (14.195214120071231, 0.8388)  (44.23375456195849, 0.4425)   \n",
       "  3   (92.17872999659934, 0.0012)  (97.04303626476803, 0.0006)   \n",
       "  4    (60.91412796408466, 0.057)  (39.00983918378642, 0.2932)   \n",
       "  \n",
       "                 Price_Booking518              Price_Booking519  \\\n",
       "  0   (48.73808820675718, 0.1592)  (12.213765932305831, 0.8287)   \n",
       "  1   (72.41102332280923, 0.0994)   (39.81837685219315, 0.4723)   \n",
       "  2   (83.32192167215457, 0.0709)   (54.16402788999447, 0.3136)   \n",
       "  3  (2.4528886659984206, 0.9133)    (59.1714243644762, 0.0596)   \n",
       "  4   (19.47406031706128, 0.6919)     (94.582862203968, 0.0012)   \n",
       "  \n",
       "                 Price_Booking520  \n",
       "  0   (50.82865199262406, 0.1387)  \n",
       "  1   (88.06567678260058, 0.0348)  \n",
       "  2  (25.087128491645018, 0.7394)  \n",
       "  3   (61.30086613145307, 0.0492)  \n",
       "  4   (35.19505761977505, 0.3708)  \n",
       "  \n",
       "  [5 rows x 524 columns],\n",
       "                Long          Lat        Light\n",
       "  count  2000.000000  2000.000000  2000.000000\n",
       "  mean      1.004000    -0.875000     0.499500\n",
       "  std      34.078683    34.782356     0.500125\n",
       "  min     -60.000000   -60.000000     0.000000\n",
       "  25%     -28.000000   -31.000000     0.000000\n",
       "  50%       2.000000     0.000000     0.000000\n",
       "  75%      30.000000    29.000000     1.000000\n",
       "  max      60.000000    60.000000     1.000000,\n",
       "  Long                 int64\n",
       "  Lat                  int64\n",
       "  Size                object\n",
       "  Light                int64\n",
       "  Price_Booking1      object\n",
       "                       ...  \n",
       "  Price_Booking516    object\n",
       "  Price_Booking517    object\n",
       "  Price_Booking518    object\n",
       "  Price_Booking519    object\n",
       "  Price_Booking520    object\n",
       "  Length: 524, dtype: object))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datac_path = 'data.csv'\n",
    "benchmark_data_path = 'benchmark_data.csv'\n",
    "\n",
    "datac = pd.read_csv(datac_path)\n",
    "benchmark_data = pd.read_csv(benchmark_data_path)\n",
    "\n",
    "datac_info = datac.head(), datac.describe(), datac.dtypes\n",
    "benchmark_data_info = benchmark_data.head(), benchmark_data.describe(), benchmark_data.dtypes\n",
    "\n",
    "datac_info, benchmark_data_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aafcf59-8ce6-4669-8dcc-ec46e3900a93",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e99324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                Price_Booking1  Price_Booking1_price  \\\n",
       " 0  (25.82068271676904, 0.7519)             25.820683   \n",
       " 1   (60.5614418412558, 0.0441)             60.561442   \n",
       " 2  (64.77841886497515, 0.0978)             64.778419   \n",
       " 3  (43.51319658191266, 0.5933)             43.513197   \n",
       " 4  (9.023792361018867, 0.9172)              9.023792   \n",
       " \n",
       "    Price_Booking1_booking_rate  \n",
       " 0                       0.7519  \n",
       " 1                       0.0441  \n",
       " 2                       0.0978  \n",
       " 3                       0.5933  \n",
       " 4                       0.9172  ,\n",
       "                  Price_Booking1  Price_Booking1_price  \\\n",
       " 0   (44.07422740778878, 0.2244)             44.074227   \n",
       " 1  (27.403085749044997, 0.6838)             27.403086   \n",
       " 2   (32.49922734531039, 0.6368)             32.499227   \n",
       " 3   (92.82272915578096, 0.0011)             92.822729   \n",
       " 4   (49.80177382910645, 0.1483)             49.801774   \n",
       " \n",
       "    Price_Booking1_booking_rate  \n",
       " 0                       0.2244  \n",
       " 1                       0.6838  \n",
       " 2                       0.6368  \n",
       " 3                       0.0011  \n",
       " 4                       0.1483  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_price_booking(data, column_name):\n",
    "    \"\"\" Parse the price and booking rate from the tuple stored as a string in the specified column. \"\"\"\n",
    "    data[f\"{column_name}_price\"], data[f\"{column_name}_booking_rate\"] = zip(\n",
    "        *data[column_name].apply(ast.literal_eval))\n",
    "    return data\n",
    "\n",
    "datac = parse_price_booking(datac, 'Price_Booking1')\n",
    "benchmark_data = parse_price_booking(benchmark_data, 'Price_Booking1')\n",
    "\n",
    "parsed_datac = datac[['Price_Booking1', 'Price_Booking1_price', 'Price_Booking1_booking_rate']].head()\n",
    "parsed_benchmark_data = benchmark_data[['Price_Booking1', 'Price_Booking1_price', 'Price_Booking1_booking_rate']].head()\n",
    "\n",
    "parsed_datac, parsed_benchmark_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b878727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_price_booking(data, week_numbers):\n",
    "    \"\"\" Parse the price and booking rate from the tuple stored as a string for specified week columns. \"\"\"\n",
    "    new_columns = {}\n",
    "\n",
    "    for week in week_numbers:\n",
    "        column_name = f'Price_Booking{week}'\n",
    "        try:\n",
    "            if column_name in data.columns:\n",
    "                prices, booking_rates = zip(*data[column_name].apply(lambda x: tuple(map(float, ast.literal_eval(x)))))\n",
    "                new_columns[f\"{column_name}_price\"] = prices\n",
    "                new_columns[f\"{column_name}_booking_rate\"] = booking_rates\n",
    "        except ValueError as e:\n",
    "            print(f\"Error parsing {column_name}: {e}\")\n",
    "\n",
    "    new_data = pd.DataFrame(new_columns)\n",
    "    return pd.concat([data, new_data], axis=1)\n",
    "\n",
    "datac = pd.read_csv('datac.csv')\n",
    "benchmark_data = pd.read_csv('benchmark_data.csv')\n",
    "week_numbers = range(1, 521)  \n",
    "\n",
    "datac = parse_price_booking(datac, week_numbers)\n",
    "benchmark_data = parse_price_booking(benchmark_data, week_numbers)\n",
    "\n",
    "datac.to_csv('updated_datac.csv', index=False)\n",
    "benchmark_data.to_csv('updated_benchmark_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda6f2df-3557-4480-bc69-433cf1217414",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c009ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([8000, 3123])\n",
      "y_train shape: torch.Size([8000])\n",
      "X_test shape: torch.Size([2000, 3123])\n",
      "y_test shape: torch.Size([2000])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('updated_datac.csv')\n",
    "\n",
    "def parse_tuples(data, columns):\n",
    "    new_cols = {}\n",
    "    for column in columns:\n",
    "        if column in data.columns:\n",
    "            prices, rates = zip(*data[column].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else (None, None)))\n",
    "            new_cols[column + '_price'] = pd.to_numeric(prices, errors='coerce')\n",
    "            new_cols[column + '_rate'] = pd.to_numeric(rates, errors='coerce')\n",
    "    return pd.DataFrame(new_cols)\n",
    "\n",
    "price_booking_cols = [col for col in df.columns if 'Price_Booking' in col]\n",
    "new_columns_df = parse_tuples(df, price_booking_cols)\n",
    "\n",
    "df.drop(price_booking_cols, axis=1, inplace=True)\n",
    "df = pd.concat([df, new_columns_df], axis=1)\n",
    "\n",
    "size_mapping = {'small': 1, 'medium': 2, 'large': 3}\n",
    "df['Size'] = df['Size'].map(size_mapping)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numerical_features = ['Long', 'Lat', 'Size', 'Light']\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "df.fillna(df.median(), inplace=True)\n",
    "\n",
    "target = 'Price_Booking1_price'\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.tensor(train_df.drop(target, axis=1).values).float()\n",
    "y_train = torch.tensor(train_df[target].values).float()\n",
    "X_test = torch.tensor(test_df.drop(target, axis=1).values).float()\n",
    "y_test = torch.tensor(test_df[target].values).float()\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2108ba7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 887.4035815429687\n",
      "Epoch 11, Loss: 791.3966025390625\n",
      "Epoch 21, Loss: 786.673716796875\n",
      "Epoch 31, Loss: 773.5852888183593\n",
      "Epoch 41, Loss: 762.0447426757812\n",
      "Epoch 51, Loss: 755.707796875\n",
      "Epoch 61, Loss: 738.5658662109375\n",
      "Epoch 71, Loss: 726.3125808105468\n",
      "Epoch 81, Loss: 599.1912939453125\n",
      "Epoch 91, Loss: 198.05922399902343\n",
      "Test Loss: 189.18678283691406\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network class\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, input_features, hidden_units, output_features):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_features, hidden_units)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(hidden_units, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.layer1(x))\n",
    "        x = self.relu2(self.layer2(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "input_features = 3123\n",
    "hidden_units = 128\n",
    "output_features = 1\n",
    "model = DenseNet(input_features, hidden_units, output_features)\n",
    "\n",
    "# Preprocess the data to handle NaN values\n",
    "X_train[X_train != X_train] = 0  \n",
    "X_test[X_test != X_test] = 0     \n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders for training data\n",
    "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.unsqueeze(1))\n",
    "        if torch.isnan(loss):\n",
    "            print(f'NaN loss detected at epoch {epoch + 1}, batch {i+1}')\n",
    "            continue\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "    test_loss = criterion(predictions, y_test.unsqueeze(1))\n",
    "print(f'Test Loss: {test_loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab44e19-71da-4597-ba62-2a185a605265",
   "metadata": {},
   "source": [
    "The training loss is decreasing over epochs, indicating that the model is learning. The test loss at the end gives an indication of how well the model generalizes to unseen data. Lower test loss generally indicates better generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa62a836-029f-4409-b15a-4e7221a1ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predicted prices\n",
    "predicted_prices = predictions.numpy().flatten()\n",
    "\n",
    "# Save the predicted prices to a new CSV file\n",
    "with open('output_benchmark_data.csv', 'w') as file:\n",
    "    for price in predicted_prices:\n",
    "        file.write(f'{price}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "439221bc-8c6a-4a5c-8062-57b7f8ae19ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_196436/4156540812.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_fold_train_tensor = torch.tensor(X_fold_train).float()\n",
      "/tmp/ipykernel_196436/4156540812.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_fold_val_tensor = torch.tensor(X_fold_val).float()\n",
      "/tmp/ipykernel_196436/4156540812.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_fold_train_tensor = torch.tensor(y_fold_train).float()\n",
      "/tmp/ipykernel_196436/4156540812.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_fold_val_tensor = torch.tensor(y_fold_val).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2...\n",
      "Fold 3...\n",
      "Fold 4...\n",
      "Fold 5...\n",
      "Fold 6...\n",
      "Fold 7...\n",
      "Fold 8...\n",
      "Fold 9...\n",
      "Fold 10...\n",
      "Average MSE: 830.2636474609375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def calculate_mse(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test)\n",
    "        mse = criterion(predictions, y_test.unsqueeze(1))\n",
    "    return mse.item()\n",
    "\n",
    "\n",
    "# Set the number of folds\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize the KFold object\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the list to store MSE values\n",
    "mse_values = []\n",
    "\n",
    "# Iterate through the folds\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Fold {fold + 1}...\")\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n",
    "    y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # Convert the data to tensors\n",
    "    X_fold_train_tensor = torch.tensor(X_fold_train).float()\n",
    "    X_fold_val_tensor = torch.tensor(X_fold_val).float()\n",
    "    y_fold_train_tensor = torch.tensor(y_fold_train).float()\n",
    "    y_fold_val_tensor = torch.tensor(y_fold_val).float()\n",
    "\n",
    "    # Train the model on the current fold\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    for epoch in range(epochs):\n",
    "        outputs = model(X_fold_train_tensor)\n",
    "        loss = criterion(outputs, y_fold_train_tensor.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the model on the current fold\n",
    "    mse = calculate_mse(model, X_fold_val_tensor, y_fold_val_tensor)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "# Calculate the average MSE\n",
    "average_mse = np.mean(mse_values)\n",
    "print(f\"Average MSE: {average_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c3e1d1-7c2d-415c-876a-a03c511ba50a",
   "metadata": {},
   "source": [
    "I don't know why MSE is so high 🥲(obviously something is wrong with model prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15e3cf-5f8b-4b05-af03-87cd71226df1",
   "metadata": {},
   "source": [
    "### Another solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aef65150-4856-4ec3-be2c-36a55ddfdfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 23:22:47.141442: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 23:22:48.706586: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/tmp/ipykernel_196436/1691419621.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Size'] = df['Size'].replace('small', 1).replace('medium', 2).replace('large', 3).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_196436/1691419621.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X['revenue'] = X[revenue_cols].max(axis=1)\n",
      "/home/marina/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2170.7627 - val_loss: 167.4310\n",
      "Epoch 2/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 452.8838 - val_loss: 303.5526\n",
      "Epoch 3/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 332.3837 - val_loss: 387.9330\n",
      "Epoch 4/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.5214 - val_loss: 181.7452\n",
      "Epoch 5/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.2221 - val_loss: 259.0750\n",
      "Epoch 6/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255.7085 - val_loss: 420.9577\n",
      "Epoch 7/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 243.5995 - val_loss: 303.6208\n",
      "Epoch 8/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 256.0605 - val_loss: 114.3390\n",
      "Epoch 9/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 234.2910 - val_loss: 461.2492\n",
      "Epoch 10/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 226.2574 - val_loss: 218.9967\n",
      "Epoch 11/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.4931 - val_loss: 251.8048\n",
      "Epoch 12/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 230.9489 - val_loss: 449.8340\n",
      "Epoch 13/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.4872 - val_loss: 461.5879\n",
      "Epoch 14/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.0001 - val_loss: 438.8583\n",
      "Epoch 15/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.2007 - val_loss: 387.4357\n",
      "Epoch 16/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175.1940 - val_loss: 411.2783\n",
      "Epoch 17/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184.7280 - val_loss: 480.7035\n",
      "Epoch 18/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.7544 - val_loss: 421.6983\n",
      "Epoch 19/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184.7320 - val_loss: 548.8732\n",
      "Epoch 20/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.5363 - val_loss: 281.5350\n",
      "Epoch 21/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.0945 - val_loss: 359.3026\n",
      "Epoch 22/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172.4867 - val_loss: 337.2923\n",
      "Epoch 23/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167.7637 - val_loss: 332.3752\n",
      "Epoch 24/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 162.2996 - val_loss: 170.6263\n",
      "Epoch 25/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176.5672 - val_loss: 268.5977\n",
      "Epoch 26/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175.9589 - val_loss: 389.9442\n",
      "Epoch 27/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172.4612 - val_loss: 557.9976\n",
      "Epoch 28/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 164.6713 - val_loss: 278.9503\n",
      "Epoch 29/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167.0799 - val_loss: 481.2812\n",
      "Epoch 30/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154.5813 - val_loss: 326.2224\n",
      "Epoch 31/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 163.2741 - val_loss: 264.4262\n",
      "Epoch 32/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 166.6615 - val_loss: 467.0944\n",
      "Epoch 33/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.6699 - val_loss: 251.9025\n",
      "Epoch 34/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.5071 - val_loss: 378.5175\n",
      "Epoch 35/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157.0652 - val_loss: 356.9894\n",
      "Epoch 36/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148.7973 - val_loss: 276.2967\n",
      "Epoch 37/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.6797 - val_loss: 471.9628\n",
      "Epoch 38/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.1687 - val_loss: 472.3744\n",
      "Epoch 39/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.0871 - val_loss: 298.0586\n",
      "Epoch 40/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.0279 - val_loss: 263.1827\n",
      "Epoch 41/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145.2396 - val_loss: 392.1750\n",
      "Epoch 42/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.0209 - val_loss: 376.0810\n",
      "Epoch 43/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134.6247 - val_loss: 339.3189\n",
      "Epoch 44/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.6660 - val_loss: 496.0426\n",
      "Epoch 45/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.5085 - val_loss: 232.3866\n",
      "Epoch 46/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145.7490 - val_loss: 353.2283\n",
      "Epoch 47/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.2784 - val_loss: 350.5317\n",
      "Epoch 48/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.7118 - val_loss: 221.6234\n",
      "Epoch 49/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143.5184 - val_loss: 317.4146\n",
      "Epoch 50/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 130.9519 - val_loss: 653.5750\n",
      "Epoch 51/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.0288 - val_loss: 329.1237\n",
      "Epoch 52/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.7848 - val_loss: 378.4469\n",
      "Epoch 53/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.6056 - val_loss: 420.9746\n",
      "Epoch 54/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.5709 - val_loss: 166.7093\n",
      "Epoch 55/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.0493 - val_loss: 304.0504\n",
      "Epoch 56/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134.0829 - val_loss: 571.1602\n",
      "Epoch 57/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.5460 - val_loss: 215.0399\n",
      "Epoch 58/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.2685 - val_loss: 362.3520\n",
      "Epoch 59/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.0959 - val_loss: 383.1043\n",
      "Epoch 60/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.5311 - val_loss: 624.4705\n",
      "Epoch 61/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.9406 - val_loss: 326.5827\n",
      "Epoch 62/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132.1022 - val_loss: 227.3740\n",
      "Epoch 63/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142.6665 - val_loss: 352.9135\n",
      "Epoch 64/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.2695 - val_loss: 224.1821\n",
      "Epoch 65/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.3209 - val_loss: 369.9724\n",
      "Epoch 66/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.3404 - val_loss: 384.1600\n",
      "Epoch 67/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.9042 - val_loss: 326.0604\n",
      "Epoch 68/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.3724 - val_loss: 270.0277\n",
      "Epoch 69/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.7477 - val_loss: 345.9091\n",
      "Epoch 70/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.2463 - val_loss: 205.8707\n",
      "Epoch 71/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.2565 - val_loss: 310.3615\n",
      "Epoch 72/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.0156 - val_loss: 427.3998\n",
      "Epoch 73/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.8918 - val_loss: 301.0708\n",
      "Epoch 74/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.8457 - val_loss: 306.4225\n",
      "Epoch 75/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.9553 - val_loss: 403.0758\n",
      "Epoch 76/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.0603 - val_loss: 391.8873\n",
      "Epoch 77/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.9744 - val_loss: 284.0841\n",
      "Epoch 78/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.8484 - val_loss: 545.5733\n",
      "Epoch 79/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.0046 - val_loss: 373.4970\n",
      "Epoch 80/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.3611 - val_loss: 412.1659\n",
      "Epoch 81/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.4151 - val_loss: 237.6397\n",
      "Epoch 82/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.6710 - val_loss: 280.3649\n",
      "Epoch 83/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.9553 - val_loss: 402.7234\n",
      "Epoch 84/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.3746 - val_loss: 440.0606\n",
      "Epoch 85/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.7912 - val_loss: 427.2871\n",
      "Epoch 86/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.2267 - val_loss: 454.0159\n",
      "Epoch 87/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.9037 - val_loss: 497.8654\n",
      "Epoch 88/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103.2564 - val_loss: 369.0179\n",
      "Epoch 89/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.2980 - val_loss: 305.7045\n",
      "Epoch 90/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.6576 - val_loss: 509.3549\n",
      "Epoch 91/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.0282 - val_loss: 266.7000\n",
      "Epoch 92/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.3829 - val_loss: 273.1202\n",
      "Epoch 93/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.1108 - val_loss: 130.4011\n",
      "Epoch 94/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.9665 - val_loss: 227.6989\n",
      "Epoch 95/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.4318 - val_loss: 227.5365\n",
      "Epoch 96/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.0095 - val_loss: 278.1858\n",
      "Epoch 97/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.0075 - val_loss: 408.3693\n",
      "Epoch 98/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.8705 - val_loss: 359.4463\n",
      "Epoch 99/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103.3776 - val_loss: 174.5379\n",
      "Epoch 100/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 129.0349 - val_loss: 342.0693\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import re\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "# Load the benchmark_data.csv file\n",
    "df = pd.read_csv('benchmark_data.csv')\n",
    "\n",
    "# Handle the non-numeric values in the 'Size' column\n",
    "df['Size'] = df['Size'].replace('small', 1).replace('medium', 2).replace('large', 3).astype(float)\n",
    "\n",
    "# Convert the relevant columns to the correct data types\n",
    "df['Long'] = df['Long'].astype(int)\n",
    "df['Lat'] = df['Lat'].astype(int)\n",
    "df['Size'] = df['Size'].astype(float)\n",
    "df['Light'] = df['Light'].astype(int)\n",
    "\n",
    "for i in range(1, 521):\n",
    "    col_name = f'Price_Booking{i}'\n",
    "    if df[col_name].dtype == 'object':\n",
    "        df[col_name] = df[col_name].apply(lambda x: float(re.findall(r'-?\\d+\\.?\\d*', str(x))[0]) if isinstance(x, str) else x)\n",
    "\n",
    "# Select the relevant features\n",
    "X = df[['Long', 'Lat', 'Size', 'Light'] + [f'Price_Booking{i}' for i in range(1, 521)]]\n",
    "\n",
    "# Calculate the revenue as the maximum price among all bookings\n",
    "revenue_cols = [f'Price_Booking{i}' for i in range(1, 521)]\n",
    "X['revenue'] = X[revenue_cols].max(axis=1)\n",
    "y = X['revenue']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X.drop('revenue', axis=1), y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Model Development\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X.shape[1]-1, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# 3. Optimal Price Prediction\n",
    "# Use the trained model to predict the optimal price for the first week of 2024\n",
    "X_2024 = df[['Long', 'Lat', 'Size', 'Light'] + [f'Price_Booking{i}' for i in range(1, 521)]]\n",
    "optimal_prices = model.predict(X_2024).flatten()\n",
    "\n",
    "# 4. Output Generation\n",
    "# Create the output_benchmark_data.csv file\n",
    "np.savetxt('output_benchmark_data1.csv', optimal_prices, delimiter=',', fmt='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d8732-c616-45bf-99e1-76df546306b8",
   "metadata": {},
   "source": [
    "I like the prevous solution more but I am just living this one here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda7aadd-211a-4cad-866a-196841870830",
   "metadata": {},
   "source": [
    "To be honest I am very curious about your solution and the correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29adecb5-52a7-4afe-b89d-21fef9852bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
